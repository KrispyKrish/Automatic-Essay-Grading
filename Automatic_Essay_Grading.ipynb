{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRpr4GbPYRbK",
    "outputId": "3f25dbb5-245b-4d4e-86fd-fef26542f97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9CxvInsl1Ca",
    "outputId": "413ec720-a5fa-47f8-8756-0b6e0baccaa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras.models in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras.models) (2.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras.models) (1.26.4)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from keras.models) (3.7.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from keras.models) (11.0.0)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from keras.models) (4.10.0.84)\n",
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (from keras.models) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (0.15.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (4.66.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->keras.models) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->keras.models) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->keras.models) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->keras.models) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->keras.models) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy->keras.models) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->keras.models) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->keras.models) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->keras.models) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->keras.models) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->keras.models) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->keras.models) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->keras.models) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->keras.models) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->keras.models) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->keras.models) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->keras.models) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->keras.models) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->keras.models) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "pip install keras.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-MFa-GCAYG2_",
    "outputId": "91f6b47a-f717-4aa8-a82e-ff09e8694ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.3.25)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.68.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.12.1)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (18.1.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (24.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.37.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.17.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.45.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
      "Requirement already satisfied: keras==2.10.0 in /usr/local/lib/python3.10/dist-packages (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.10.0 \n",
    "!pip install keras==2.10.0 \n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras import models\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5HgBa6xYG3B"
   },
   "source": [
    "**Preparing Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZQxZgTgYG3C"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"training_set_rel3.tsv\", sep='\\t', encoding='ISO-8859-1');\n",
    "df.dropna(axis=1,inplace=True)\n",
    "df.drop(columns=['rater1_domain1','rater2_domain1'],inplace=True,axis=1)\n",
    "df.head()\n",
    "temp = pd.read_csv(\"Processed_data.csv\")\n",
    "temp.drop(\"Unnamed: 0\",inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "thOMnYn3YG3D",
    "outputId": "3095d8c5-4e8e-4162-b954-6b7e3488de7c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 12976,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6309,\n        \"min\": 1,\n        \"max\": 21633,\n        \"num_unique_values\": 12976,\n        \"samples\": [\n          9908,\n          9872,\n          305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_set\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12972,\n        \"samples\": [\n          \"The features of the setting affect the cyclist in many ways. He is riding his bike along the road and encounters a dilema.\\u0094\\u0085 @CAPS1 weeds crossed my path and a ridiculously large snake. Blocked the\\u0085 pavement in front of me.\\u0094 He had to stop and into by the snake which showed him down and freaked him out. He had problems with thirst already and had to deal with a snake that \\u0093really did look like a diamondback.\\u0094 @CAPS2, he sees a building up ahead and discovers that it\\u0092s a walrus Grape Juice factory. He thought that is might have some water but realized it was abandoned. Relating to his thirst, before he left he grabbed some pebbles.\\u0094 I\\u0092d read once that sucking on stones helps takes your mind off thirst by allowing what spit you have left to circulate.\\u0094 * @CAPS3 he came across a fishing camp and received instructions on how to go on. This affected him because he @CAPS3 got to a secure place and got proper directions and will learn from his mistake of listening to the older men at the beginning. The features of \",\n          \"The author concludes the story with this paragraph because the cold was brufield or the  author never  wanted to be around while the cold was in sesion. At the  time it was realy cold\",\n          \"Computers, a very much talked about subject. Did you know that @PERCENT1 of homes in @LOCATION1 own at least one computer. And that goes for about @PERCENT2 in @LOCATION2. Some people don't like that this is true, but on the other hand some people do. I have a computer, it can do so much, for example it can help me with writing, I can play games on it and socialize with social networking sites and \\\"I.M.'s\\\", it can even help me order a product form a website like @ORGANIZATION1, @LOCATION3, or @LOCATION4. Like I said, I have a computer and I can use it to help me write. At school in english, I would use my computer to help me with a writing prompt. I also use it to write conclusions for science labs. There are a lot of other kids that do this as well, it really is very helpful. That is only one of the reasons I think computers are beneficial to society. Another reason I think computers are beneficial to society is because you can play games on them, like \\\"world of warcraft\\\", \\\"@CAPS1 @CAPS2 @NUM1\\\", or classics like \\\"@CAPS3 @CAPS4 @CAPS5\\\". There are millions of people that play games on the computer. Also you can socialize with social networking sites, like @CAPS6 and twitter, and also because you can \\\"I.M.\\\" your friends. I.M. stands for @CAPS7 messaging, and it is kind of like email except it is just about instantaneous, and so you and friend can have a conversation over the computer. Also there is video chatting, where it is kind of like a phone except you can see the person you're talking to and it is over the computer, so it is almost like you and the person you are videochatting with are meeting face to face, but your not. A third reason I feel that computers are beneficial to society is because you can order a product over the internet form shop websites. For example, I got my @CAPS8 from @LOCATION3, and also the bulb for a @CAPS9 in my house is wearing out, so my dad is going to buy a @LOCATION1 bulb on @ORGANIZATION1. It is things like this that make life that much easier for the @CAPS10 @PERSON1, because this way these people don't have to drive to the store to buy something, that is, if they can wait a week or two for the product to arrive. These are the kinds of things that make me feel that computers are beneficial to society. I know they might not be the best reasons, but they are quite important to me. Being able to type essays, play games and socialize, and order products form websites is just amazing. These are some of the reasons that I and others love computers. But I have a question for you, why do you like or dislike computers?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"domain1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          10,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3de57fa0-144d-449d-a7c6-ec42824c8893\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3de57fa0-144d-449d-a7c6-ec42824c8893')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3de57fa0-144d-449d-a7c6-ec42824c8893 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3de57fa0-144d-449d-a7c6-ec42824c8893');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9afcdbc4-8550-43b2-9120-3a6708928b26\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9afcdbc4-8550-43b2-9120-3a6708928b26')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9afcdbc4-8550-43b2-9120-3a6708928b26 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              6  \n",
       "1              7  \n",
       "2              5  \n",
       "3              8  \n",
       "4              6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain1_score']=temp['final_score']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "CzMXJyyzYG3D",
    "outputId": "202a9ab8-2322-41a2-d4be-8018c7abd807"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "RPpexArsYG3E",
    "outputId": "c5154530-cd25-4eef-92bf-12b81558ba01"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"temp\",\n  \"rows\": 12976,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6309,\n        \"min\": 1,\n        \"max\": 21633,\n        \"num_unique_values\": 12976,\n        \"samples\": [\n          9908,\n          9872,\n          305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay_set\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12972,\n        \"samples\": [\n          \"The features of the setting affect the cyclist in many ways. He is riding his bike along the road and encounters a dilema.\\u0094 weeds crossed my path and a ridiculously large snake. Blocked the pavement in front of me.\\u0094 He had to stop and into by the snake which showed him down and freaked him out. He had problems with thirst already and had to deal with a snake that \\u0093really did look like a diamondback.\\u0094 he sees a building up ahead and discovers that it\\u0092s a walrus Grape Juice factory. He thought that is might have some water but realized it was abandoned. Relating to his thirst, before he left he grabbed some pebbles.\\u0094 I\\u0092d read once that sucking on stones helps takes your mind off thirst by allowing what spit you have left to circulate.\\u0094 * he came across a fishing camp and received instructions on how to go on. This affected him because he got to a secure place and got proper directions and will learn from his mistake of listening to the older men at the beginning. The features of\",\n          \"The author concludes the story with this paragraph because the cold was brufield or the author never wanted to be around while the cold was in sesion. At the time it was realy cold\",\n          \"Computers, a very much talked about subject. Did you know that of homes in own at least one computer. And that goes for about in Some people don't like that this is true, but on the other hand some people do. I have a computer, it can do so much, for example it can help me with writing, I can play games on it and socialize with social networking sites and \\\"I.M.'s\\\", it can even help me order a product form a website like or Like I said, I have a computer and I can use it to help me write. At school in english, I would use my computer to help me with a writing prompt. I also use it to write conclusions for science labs. There are a lot of other kids that do this as well, it really is very helpful. That is only one of the reasons I think computers are beneficial to society. Another reason I think computers are beneficial to society is because you can play games on them, like \\\"world of warcraft\\\", \\\"@CAPS1 or classics like \\\"@CAPS3 There are millions of people that play games on the computer. Also you can socialize with social networking sites, like and twitter, and also because you can \\\"I.M.\\\" your friends. I.M. stands for messaging, and it is kind of like email except it is just about instantaneous, and so you and friend can have a conversation over the computer. Also there is video chatting, where it is kind of like a phone except you can see the person you're talking to and it is over the computer, so it is almost like you and the person you are videochatting with are meeting face to face, but your not. A third reason I feel that computers are beneficial to society is because you can order a product over the internet form shop websites. For example, I got my from and also the bulb for a in my house is wearing out, so my dad is going to buy a bulb on It is things like this that make life that much easier for the because this way these people don't have to drive to the store to buy something, that is, if they can wait a week or two for the product to arrive. These are the kinds of things that make me feel that computers are beneficial to society. I know they might not be the best reasons, but they are quite important to me. Being able to type essays, play games and socialize, and order products form websites is just amazing. These are some of the reasons that I and others love computers. But I have a question for you, why do you like or dislike computers?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 10,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          10,\n          6,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_essay\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12972,\n        \"samples\": [\n          \"The features setting affect cyclist many ways  He riding bike along road encounters dilema weeds crossed path ridiculously large snake  Blocked pavement front me He stop snake showed freaked  He problems thirst already deal snake really look like diamondback sees building ahead discovers its walrus Grape Juice factory  He thought might water realized abandoned  Relating thirst  left grabbed pebbles Id read sucking stones helps takes mind thirst allowing spit left circulate  came across fishing camp received instructions go  This affected got secure place got proper directions learn mistake listening older men beginning  The features\",\n          \"The author concludes story paragraph cold brufield author never wanted around cold sesion  At time realy cold\",\n          \"Computers  much talked subject  Did know homes least one computer  And goes Some people nt like true  hand people  I computer  much  example help writing  I play games socialize social networking sites  IM  s   even help order product form website like Like I said  I computer I use help write  At school english  I would use computer help writing prompt  I also use write conclusions science labs  There lot kids well  really helpful  That one reasons I think computers beneficial society  Another reason I think computers beneficial society play games  like  world warcraft     CAPS classics like   CAPS There millions people play games computer  Also socialize social networking sites  like twitter  also  IM   friends  IM  stands messaging  kind like email except instantaneous  friend conversation computer  Also video chatting  kind like phone except see person re talking computer  almost like person videochatting meeting face face   A third reason I feel computers beneficial society order product internet form shop websites  For example  I got also bulb house wearing  dad going buy bulb It things like make life much easier way people nt drive store buy something   wait week two product arrive  These kinds things make feel computers beneficial society  I know might best reasons  quite important  Being able type essays  play games socialize  order products form websites amazing  These reasons I others love computers  But I question  like dislike computers \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"char_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 719,\n        \"min\": 7,\n        \"max\": 4817,\n        \"num_unique_values\": 2729,\n        \"samples\": [\n          779,\n          2927,\n          237\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 173,\n        \"min\": 2,\n        \"max\": 1056,\n        \"num_unique_values\": 842,\n        \"samples\": [\n          727,\n          560,\n          572\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sent_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 1,\n        \"max\": 90,\n        \"num_unique_values\": 78,\n        \"samples\": [\n          9,\n          16,\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_word_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.360651043035522,\n        \"min\": 2.9,\n        \"max\": 5.875,\n        \"num_unique_values\": 9181,\n        \"samples\": [\n          3.949074074074074,\n          4.255681818181818,\n          3.323529411764706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spell_err_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 71,\n        \"num_unique_values\": 63,\n        \"samples\": [\n          66,\n          60,\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"noun_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 0,\n        \"max\": 309,\n        \"num_unique_values\": 206,\n        \"samples\": [\n          69,\n          80,\n          188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adj_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 37,\n        \"min\": 0,\n        \"max\": 263,\n        \"num_unique_values\": 211,\n        \"samples\": [\n          71,\n          161,\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verb_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 83,\n        \"num_unique_values\": 82,\n        \"samples\": [\n          12,\n          18,\n          46\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"adv_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          14,\n          21,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "temp"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-4f0aceec-c6d4-4ad0-af68-a1398c30b207\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>final_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>spell_err_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>6</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>1441</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>4.188953</td>\n",
       "      <td>11</td>\n",
       "      <td>76</td>\n",
       "      <td>75</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f0aceec-c6d4-4ad0-af68-a1398c30b207')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-4f0aceec-c6d4-4ad0-af68-a1398c30b207 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-4f0aceec-c6d4-4ad0-af68-a1398c30b207');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "\n",
       "   final_score                                        clean_essay  char_count  \\\n",
       "0            6  Dear local newspaper  I think effects computer...        1441   \n",
       "\n",
       "   word_count  sent_count  avg_word_len  spell_err_count  noun_count  \\\n",
       "0         344          16      4.188953               11          76   \n",
       "\n",
       "   adj_count  verb_count  adv_count  \n",
       "0         75          18         24  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mS04qu5YG3E"
   },
   "outputs": [],
   "source": [
    "#Make Dataset\n",
    "# Create y before dropping the column\n",
    "y = df['domain1_score']\n",
    "#Now drop the column and assign X\n",
    "X = df.drop('domain1_score', inplace=False, axis=1)\n",
    "# use inplace=False to create a copy instead of modifying in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmBeqhe8YG3E"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e93lO95ZYG3F",
    "outputId": "26fb7f8a-0272-4f62-ec6f-0d942c60a796"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9083, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMe8TCeJYG3F"
   },
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR_hr2GNYG3F"
   },
   "outputs": [],
   "source": [
    "train_e = X_train['essay'].tolist()\n",
    "test_e = X_test['essay'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAT_nG-YYG3F",
    "outputId": "0f053971-9e1d-4a58-cced-27591bccc3b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "train_sents=[]\n",
    "test_sents=[]\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = []\n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "for i in train_e:\n",
    "    train_sents+=essay2word(i)\n",
    "\n",
    "for i in test_e:\n",
    "    test_sents+=essay2word(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hn0-VkiYG3G",
    "outputId": "31c7b889-6594-4b60-811a-1313add46a39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1-xlJLLYG3G",
    "outputId": "8ecd9517-612e-4b65-c749-76caa8456aae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'first',\n",
       " 'day',\n",
       " 'high',\n",
       " 'school',\n",
       " 'gut',\n",
       " 'full',\n",
       " 'butterflies',\n",
       " 'make',\n",
       " 'want',\n",
       " 'run',\n",
       " 'bathrooms',\n",
       " 'hide',\n",
       " 'world']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft7Bf8CIYG3H"
   },
   "source": [
    "**Preparing WORD2VEC and LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTjhd5cwYG3H"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHR7pJBnYG3H",
    "outputId": "eb7253aa-f2ec-4d53-ee21-b45faca80af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-a168ff01e180>:15: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  model.init_sims(replace=True)\n",
      "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "#Training Word2Vec model\n",
    "num_features = 300\n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "model = Word2Vec(train_sents,\n",
    "                 workers=num_workers,\n",
    "                 vector_size=num_features,\n",
    "                 min_count = min_word_count,\n",
    "                 window = context,\n",
    "                 sample = downsampling)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Xx4Sf3YYG3H",
    "outputId": "3d1def5b-6345-419f-c01f-040e15943a33",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-e7b011f5765d>:9: RuntimeWarning: invalid value encountered in divide\n",
      "  vec = np.divide(vec,noOfWords)\n"
     ]
    }
   ],
   "source": [
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    noOfWords = 0.\n",
    "    index2word_set = set(model.wv.index_to_key)\n",
    "    for i in words:\n",
    "        if i in index2word_set:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec,model.wv[i])\n",
    "    vec = np.divide(vec,noOfWords)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs\n",
    "\n",
    "\n",
    "clean_train=[]\n",
    "for i in train_e:\n",
    "    clean_train.append(sent2word(i))\n",
    "training_vectors = getVecs(clean_train, model, num_features)\n",
    "\n",
    "clean_test=[]\n",
    "\n",
    "for i in test_e:\n",
    "    clean_test.append(sent2word(i))\n",
    "testing_vectors = getVecs(clean_test, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2qlKUAKYG3I",
    "outputId": "65bead12-218b-46e7-f1b8-9d3884c69508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9083, 300)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H0riRqniYG3I",
    "outputId": "dd31b3e1-7503-45c7-92d8-12de15a7eaed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "training_vectors = np.array(training_vectors)\n",
    "testing_vectors = np.array(testing_vectors)\n",
    "\n",
    "if training_vectors.shape[1:] == (1, 300):\n",
    "    training_vectors = training_vectors.reshape(training_vectors.shape[0], training_vectors.shape[2])\n",
    "if testing_vectors.shape[1:] == (1, 300):\n",
    "    testing_vectors = testing_vectors.reshape(testing_vectors.shape[0], testing_vectors.shape[2])\n",
    "\n",
    "# Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "training_vectors = np.reshape(training_vectors, (training_vectors.shape[0], 1, training_vectors.shape[1]))\n",
    "testing_vectors = np.reshape(testing_vectors, (testing_vectors.shape[0], 1, testing_vectors.shape[1]))\n",
    "lstm_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wj9l--wHYG3I",
    "outputId": "0093641d-bd4f-4806-b10e-c142dc5d0a01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9083, 1, 300)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_8kDip3YG3I"
   },
   "source": [
    "\n",
    "**TRAINING AND PREDICTION**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuOuKe3SYG3J",
    "outputId": "56be3c54-a4aa-45b5-d2e4-b5a14f9fb9c0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "142/142 [==============================] - 8s 19ms/step - loss: 10.3890 - mae: 2.5202\n",
      "Epoch 2/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 5.4902 - mae: 1.8466\n",
      "Epoch 3/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 5.2380 - mae: 1.8039\n",
      "Epoch 4/150\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 5.2321 - mae: 1.8070\n",
      "Epoch 5/150\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 5.0814 - mae: 1.7786\n",
      "Epoch 6/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 5.0796 - mae: 1.7741\n",
      "Epoch 7/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.9895 - mae: 1.7606\n",
      "Epoch 8/150\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 5.0375 - mae: 1.7687\n",
      "Epoch 9/150\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 4.9143 - mae: 1.7459\n",
      "Epoch 10/150\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 4.9336 - mae: 1.7516\n",
      "Epoch 11/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.8957 - mae: 1.7432\n",
      "Epoch 12/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.8670 - mae: 1.7365\n",
      "Epoch 13/150\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 4.8024 - mae: 1.7235\n",
      "Epoch 14/150\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 4.7575 - mae: 1.7154\n",
      "Epoch 15/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.7764 - mae: 1.7158\n",
      "Epoch 16/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.6715 - mae: 1.7001\n",
      "Epoch 17/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 4.6807 - mae: 1.6981\n",
      "Epoch 18/150\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 4.7000 - mae: 1.6985\n",
      "Epoch 19/150\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 4.6244 - mae: 1.6886\n",
      "Epoch 20/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.6141 - mae: 1.6894\n",
      "Epoch 21/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.5566 - mae: 1.6671\n",
      "Epoch 22/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.5609 - mae: 1.6698\n",
      "Epoch 23/150\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 4.4747 - mae: 1.6545\n",
      "Epoch 24/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 4.4241 - mae: 1.6449\n",
      "Epoch 25/150\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 4.4505 - mae: 1.6503\n",
      "Epoch 26/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 4.4029 - mae: 1.6393\n",
      "Epoch 27/150\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 4.3955 - mae: 1.6329\n",
      "Epoch 28/150\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 4.3457 - mae: 1.6277\n",
      "Epoch 29/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.3840 - mae: 1.6381\n",
      "Epoch 30/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.3494 - mae: 1.6243\n",
      "Epoch 31/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.3197 - mae: 1.6262\n",
      "Epoch 32/150\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 4.3082 - mae: 1.6183\n",
      "Epoch 33/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 4.2004 - mae: 1.6039\n",
      "Epoch 34/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.2616 - mae: 1.6123\n",
      "Epoch 35/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 4.2231 - mae: 1.6087\n",
      "Epoch 36/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.1527 - mae: 1.5916\n",
      "Epoch 37/150\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 4.1322 - mae: 1.5886\n",
      "Epoch 38/150\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 4.1195 - mae: 1.5869\n",
      "Epoch 39/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.0617 - mae: 1.5732\n",
      "Epoch 40/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.1398 - mae: 1.5882\n",
      "Epoch 41/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.0467 - mae: 1.5722\n",
      "Epoch 42/150\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 4.0936 - mae: 1.5784\n",
      "Epoch 43/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 4.0314 - mae: 1.5692\n",
      "Epoch 44/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.0540 - mae: 1.5684\n",
      "Epoch 45/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.0333 - mae: 1.5688\n",
      "Epoch 46/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 4.0209 - mae: 1.5718\n",
      "Epoch 47/150\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 4.0272 - mae: 1.5647\n",
      "Epoch 48/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 4.0147 - mae: 1.5640\n",
      "Epoch 49/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.9326 - mae: 1.5464\n",
      "Epoch 50/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.9354 - mae: 1.5500\n",
      "Epoch 51/150\n",
      "142/142 [==============================] - 3s 24ms/step - loss: 3.9110 - mae: 1.5454\n",
      "Epoch 52/150\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 3.8911 - mae: 1.5399\n",
      "Epoch 53/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.8387 - mae: 1.5253\n",
      "Epoch 54/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.8263 - mae: 1.5271\n",
      "Epoch 55/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.8061 - mae: 1.5279\n",
      "Epoch 56/150\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 3.8239 - mae: 1.5318\n",
      "Epoch 57/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 3.8330 - mae: 1.5305\n",
      "Epoch 58/150\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 3.7912 - mae: 1.5136\n",
      "Epoch 59/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.7806 - mae: 1.5197\n",
      "Epoch 60/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.7614 - mae: 1.5167\n",
      "Epoch 61/150\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 3.7043 - mae: 1.5027\n",
      "Epoch 62/150\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 3.6793 - mae: 1.4964\n",
      "Epoch 63/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.6580 - mae: 1.4864\n",
      "Epoch 64/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.6881 - mae: 1.4996\n",
      "Epoch 65/150\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 3.7128 - mae: 1.5010\n",
      "Epoch 66/150\n",
      "142/142 [==============================] - 4s 32ms/step - loss: 3.6159 - mae: 1.4839\n",
      "Epoch 67/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 3.6538 - mae: 1.4868\n",
      "Epoch 68/150\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 3.6170 - mae: 1.4879\n",
      "Epoch 69/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5913 - mae: 1.4771\n",
      "Epoch 70/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5841 - mae: 1.4732\n",
      "Epoch 71/150\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 3.5646 - mae: 1.4749\n",
      "Epoch 72/150\n",
      "142/142 [==============================] - 3s 21ms/step - loss: 3.5993 - mae: 1.4785\n",
      "Epoch 73/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5740 - mae: 1.4703\n",
      "Epoch 74/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5776 - mae: 1.4756\n",
      "Epoch 75/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 3.5170 - mae: 1.4615\n",
      "Epoch 76/150\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 3.5538 - mae: 1.4688\n",
      "Epoch 77/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5397 - mae: 1.4641\n",
      "Epoch 78/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.4910 - mae: 1.4608\n",
      "Epoch 79/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5018 - mae: 1.4575\n",
      "Epoch 80/150\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 3.5396 - mae: 1.4658\n",
      "Epoch 81/150\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 3.4906 - mae: 1.4575\n",
      "Epoch 82/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.5016 - mae: 1.4570\n",
      "Epoch 83/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.4986 - mae: 1.4558\n",
      "Epoch 84/150\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 3.4651 - mae: 1.4507\n",
      "Epoch 85/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 3.4868 - mae: 1.4532\n",
      "Epoch 86/150\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 3.4630 - mae: 1.4518\n",
      "Epoch 87/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.4556 - mae: 1.4462\n",
      "Epoch 88/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.4154 - mae: 1.4395\n",
      "Epoch 89/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.4315 - mae: 1.4396\n",
      "Epoch 90/150\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 3.4125 - mae: 1.4311\n",
      "Epoch 91/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 3.3799 - mae: 1.4347\n",
      "Epoch 92/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3999 - mae: 1.4338\n",
      "Epoch 93/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 3.3873 - mae: 1.4286\n",
      "Epoch 94/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3657 - mae: 1.4308\n",
      "Epoch 95/150\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 3.3716 - mae: 1.4303\n",
      "Epoch 96/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 3.3388 - mae: 1.4223\n",
      "Epoch 97/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3320 - mae: 1.4140\n",
      "Epoch 98/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3649 - mae: 1.4230\n",
      "Epoch 99/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 3.3489 - mae: 1.4259\n",
      "Epoch 100/150\n",
      "142/142 [==============================] - 4s 31ms/step - loss: 3.3091 - mae: 1.4146\n",
      "Epoch 101/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3509 - mae: 1.4268\n",
      "Epoch 102/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3697 - mae: 1.4242\n",
      "Epoch 103/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2984 - mae: 1.4133\n",
      "Epoch 104/150\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 3.3342 - mae: 1.4160\n",
      "Epoch 105/150\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 3.2822 - mae: 1.4054\n",
      "Epoch 106/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2880 - mae: 1.4040\n",
      "Epoch 107/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.3111 - mae: 1.4144\n",
      "Epoch 108/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2794 - mae: 1.4121\n",
      "Epoch 109/150\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 3.2488 - mae: 1.3959\n",
      "Epoch 110/150\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 3.2905 - mae: 1.4087\n",
      "Epoch 111/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2363 - mae: 1.3974\n",
      "Epoch 112/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 3.2186 - mae: 1.3918\n",
      "Epoch 113/150\n",
      "142/142 [==============================] - 3s 20ms/step - loss: 3.2328 - mae: 1.3920\n",
      "Epoch 114/150\n",
      "142/142 [==============================] - 5s 32ms/step - loss: 3.2135 - mae: 1.3899\n",
      "Epoch 115/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2098 - mae: 1.3881\n",
      "Epoch 116/150\n",
      "142/142 [==============================] - 3s 18ms/step - loss: 3.2053 - mae: 1.3866\n",
      "Epoch 117/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2312 - mae: 1.3972\n",
      "Epoch 118/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 3.2021 - mae: 1.3904\n",
      "Epoch 119/150\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 3.2102 - mae: 1.3925\n",
      "Epoch 120/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2500 - mae: 1.3984\n",
      "Epoch 121/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1930 - mae: 1.3869\n",
      "Epoch 122/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.2089 - mae: 1.3899\n",
      "Epoch 123/150\n",
      "142/142 [==============================] - 4s 26ms/step - loss: 3.1488 - mae: 1.3769\n",
      "Epoch 124/150\n",
      "142/142 [==============================] - 4s 25ms/step - loss: 3.1715 - mae: 1.3812\n",
      "Epoch 125/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1698 - mae: 1.3782\n",
      "Epoch 126/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1814 - mae: 1.3826\n",
      "Epoch 127/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1453 - mae: 1.3816\n",
      "Epoch 128/150\n",
      "142/142 [==============================] - 4s 30ms/step - loss: 3.1664 - mae: 1.3793\n",
      "Epoch 129/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 3.1437 - mae: 1.3754\n",
      "Epoch 130/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1799 - mae: 1.3822\n",
      "Epoch 131/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1486 - mae: 1.3744\n",
      "Epoch 132/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1424 - mae: 1.3721\n",
      "Epoch 133/150\n",
      "142/142 [==============================] - 5s 33ms/step - loss: 3.0997 - mae: 1.3633\n",
      "Epoch 134/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0948 - mae: 1.3618\n",
      "Epoch 135/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1327 - mae: 1.3657\n",
      "Epoch 136/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1119 - mae: 1.3664\n",
      "Epoch 137/150\n",
      "142/142 [==============================] - 3s 22ms/step - loss: 3.0998 - mae: 1.3603\n",
      "Epoch 138/150\n",
      "142/142 [==============================] - 4s 29ms/step - loss: 3.0636 - mae: 1.3530\n",
      "Epoch 139/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1016 - mae: 1.3654\n",
      "Epoch 140/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0873 - mae: 1.3656\n",
      "Epoch 141/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.1075 - mae: 1.3664\n",
      "Epoch 142/150\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 3.0763 - mae: 1.3528\n",
      "Epoch 143/150\n",
      "142/142 [==============================] - 4s 27ms/step - loss: 3.0546 - mae: 1.3517\n",
      "Epoch 144/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0744 - mae: 1.3564\n",
      "Epoch 145/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0555 - mae: 1.3547\n",
      "Epoch 146/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0378 - mae: 1.3515\n",
      "Epoch 147/150\n",
      "142/142 [==============================] - 4s 28ms/step - loss: 3.0964 - mae: 1.3646\n",
      "Epoch 148/150\n",
      "142/142 [==============================] - 3s 23ms/step - loss: 3.0664 - mae: 1.3579\n",
      "Epoch 149/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0874 - mae: 1.3554\n",
      "Epoch 150/150\n",
      "142/142 [==============================] - 3s 19ms/step - loss: 3.0107 - mae: 1.3442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x79199e289570>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(training_vectors, y_train, batch_size=64, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DnnGO2_YG3J",
    "outputId": "f8595ead-201b-46df-b72f-805fe8dd1bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [4.],\n",
       "       [6.],\n",
       "       ...,\n",
       "       [7.],\n",
       "       [7.],\n",
       "       [9.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.save('final_lstm.h5')\n",
    "y_pred = lstm_model.predict(testing_vectors)\n",
    "y_pred = np.around(y_pred)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
